\section{Experiments Evaluation}
\label{sec:experiments-evaluation}

An important part of the experiments is how to evaluate which configuration of parameters is better in which scenario. We will be measuring two performance metrics that are relevant for each situation.

\subsection{Target Detection Performance Metric}
\label{subsec:target-detection-performance-metric}
This first metric, $tdp$, measures performance of the target detection.
We compute $tdp$ in equation~\ref{eq:target_detection_metric} as an average distance between the ground truth for the target and the final detection made by Fides at the end of the simulation.
We use the following notation: $\tau$ is the set of targets in the simulation, $GS_{T}$ is the ground truth score of the target, $S^{k_{max}}_{T}$ is then the aggregated score (section~\ref{sec:network-intelligence-aggregation}) for the given target computed by Fides at the end of the simulation.

\begin{equation}
\begin{split}
    tdp = \frac{1}{|\tau|} \sum_{T \in \tau}\left|GS_{T} - S^{k_{max}}_{T} \right|
\end{split}
\label{eq:target_detection_metric}
\end{equation}

\noindent
This metric provides information on how good Fides was in computing the score (malicious / benign) for some target.
It holds that $0 \leq tdp \leq 2$ where $0$ is the best detection and $2$ is the worst detection.
Moreover, if $tdp \le 1$ the Fides was on average able identify all targets correctly.

\subsection{Peer's Behavior Detection Performance Metric}
\label{subsec:peers-behavior-detection-performance-metric}

The peer's behavior detection performance metric $pbdp$ measures how close was the trust model's service trust value for the remote peer to the peer's real behavior in the simulation.
We measure it in~\ref{eq:peers_behavior_detection_metric} as an average distance between computed service trust and the ground truth behavior of the peer in the simulation.

\begin{equation}
\begin{split}
    pbdp = \frac{1}{|P|} \sum_{j \in P}\left|\bar{b_{j}} - st^{k_{max}}_{i, j} \right|
\end{split}
\label{eq:peers_behavior_detection_metric}
\end{equation}

$P$ is the set of remote peers in the simulation, $st^{k_{max}}_{i, j}$ is the service trust that the local trust model (\textit{i}) had for the remote peer (\textit{j}) at the end of the simulation.
$\bar{b_{j}}$ is then the ground truth behavior of the remote peer and we compute it in the equation \ref{eq:ground_truth_peer_behavior}.

\begin{equation}
    \begin{split}
    \bar{b_{j}} &= \frac{1 + shift \cdot \mu^{b}_{s}}{2}
    \end{split}
    \label{eq:ground_truth_peer_behavior}
\end{equation}

Recall the description of the peers' behaviors from the section \ref{sec:peers-behavioral-patterns}, where each peer's behavior $b$ had $\mu^{b}_{s}$ that was used during threat intelligence sampling.
Because the sampled score is $<-1; 1>$ and service trust $<0; 1>$, we can not use the $\mu^{b}_{s}$ directly, but we need to scale it to the correct interval.
Moreover, as malicious and incorrect peers  do have $\mu^{b}_{s}$ on the opposite scale that the ground truth is, we need to shift it before normalizing it.
For that reason, $shift = -1$ for malicious and incorrect peers and $shift = 1$ for confident correct, and uncertain behaviors and thus the equation \ref{eq:ground_truth_peer_behavior}.

\subsection{Environment Hardness}
\label{subsec:environment-hardness}
In order to be able measure how \textit{hard} it is for Fides to operate in some environment, we designed the environment hardness variable $eh$.
It holds that $0 \leq eh \leq 10$ and the higher the value is, the easier is for Fides to operate in such environment as there are more confident correct peers that provide correct threat intelligence and recommendations.
On the contrary, the lower the $eh$ is, the harder it is for Fides to operate as there are more byzantine peers.

\begin{equation}
    \begin{split}
    eh &= 10 \cdot \frac{|P_{CC}|}{|P|} + \frac{|P_{UP}|}{|P|}
    \end{split}
    \label{eq:environment_hardness}
\end{equation}

\noindent
Where $P_{CC}$ is a set of peers in simulation that behave like a confident correct (section~\ref{subsubsec:confident-correct-peer}) peer and $P_{UP}$ that behave like an uncertain peer (section~\ref{subsubsec:uncertain-peer}).

\section{Simulation Execution}
\label{sec:simulations-execution}
The simulations and experiments were designed to evaluate the trust model in multiple ways and environments.
In order to run arbitrary scenarios, we developed a framework, that allows us to simulate virtually any environment with various combinations of Fides configuration.

Unfortunately, it is not possible to run and evaluate all possible scenarios, as there are 14 different sets of parameters that can have many different values.
This leads to a combinatorial explosion and therefore we were unable to cover all possible existing scenarios. 
However, alongside the Fides implementation, we published the simulation framework as well, so anybody can simulate their preferred scenarios.

In the next chapter (\ref{ch:results}) we describe how we evaluated the experiments and what we learned about the trust model behavior in various environments with focus on the evaluation of Fides's resilience.