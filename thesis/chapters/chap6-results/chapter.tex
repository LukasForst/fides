\chapter{Results}
\label{ch:results}
This chapter presents and evaluates the results of the simulations that were designed in the previous Chapter~\ref{ch:experiments}. Since there are too many different scenarios to evaluate each setup thoroughly, we mainly focus on evaluating Fides under specific conditions that verify its resilience. These conditions are the more important for the administrator, such as situations with many byzantine peers.

The evaluation focus on finding a scenario where there are as many adversarial peers as possible, and Fides is still able to guarantee that it can come up with the correct target score. This is worst case scenario that every trust model should be evaluated under, since there is no point in evaluating a situation only with good and trusted peers.

However, since the reader may be interested in trying different scenarios, we developed and published a simulation framework~\cite{fidesGithub} where anyone can verify and simulate any scenario they are interested in.

Note that all figures in this chapter can be replicated by re-running the simulation Python code in $simulations/cases/figures$~\cite{fidesGithub}.
The graphs may differ slightly because the threat intelligence and recommendations are sampled from a probability distribution as described in Section~\ref{sec:sampling-threat-intelligence}, but the overall results should be the same.

\input{chapters/chap6-results/general_overview}

\input{chapters/chap6-results/resilience}

\input{chapters/chap6-results/considerations}


\section{Discussion}
\label{sec:discussion}
We discovered that actually there \textbf{exists} a particular setup that guarantees that Fides is able to eventually classify the targets correctly in a very adversarial situation. When Fides communicates with at least 25\% of pre-trusted peers from pre-trusted organizations ($0.25 \cdot |P|$ are pre-trusted) and uses $DistanceBasedTIEvaluation$ (Section~\ref{subsec:distance-based-eval}) for evaluating the interactions in combination with $AverageConfidenceTIAggregation$ (Section~\ref{subsec:AverageConfidenceTIAggregation}) for aggregating the threat intelligence; then Fides is able to correctly classify the targets no matter how many adversarial peers are in the network (up to filling the remaining 75\%) or how hard they lie.

We included the graph of this case, similar to the Figure~\ref{fig:single-simulation-example}, with this particular \textit{"winning"} setup in the most hostile environment to the Appendix in Figure~\ref{fig:worst-best-scenario}. For the explanation of the graph see Section~\ref{sec:general-overview-of-simulation-output}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/misclassification_score.png}
    \caption{Score in figure~\ref{fig:missclassification-recovery}.}
    \label{fig:missclassification-score-only}
\end{figure}

Interestingly, in this particular case, the initial reputation does not affect the final outcome of the simulation, but it does affect the progress as when using an initial reputation higher than $0$, Fides provides wrong scores in the situation when the malicious peers started to lie.
However, \textit{in time} it discovers that the peers are lying, which decreases their service trust and is able to eventually recover the correct labels for the targets.
The score value over time for this situation can be seen in Figure~\ref{fig:missclassification-score-only}.
We included the whole graph in the Appendix in Figure~\ref{fig:missclassification-recovery}.

With no pre-trusted peers in the network, the results of each configuration vary and they highly depend on the network topology as well as on the knowledge of the local Slips instance. The results for the no pre-trusted scenario are shown in Appendix Figure~\ref{fig:performance-all-setups-0-pretrusted}.

In the scenario of 50\% pre-trusted peers, no matter the configuration, Fides was eventually able to determine the correct target classification with a high precision of $tdp \leq 0.7$. Moreover, Fides was able to correctly identify the peer's behavior with the precision of $pbdp \leq 0.2$. This is a very favorable situation for the administrator, where you trust the peers so much that it is not possible for the adversarial peers to modify the belief. The results for this scenario are shown in Appendix Figure~\ref{fig:performance-all-setups-50-pretrusted}.

\bigskip
In general, for a case with no pre-trusted peers and organizations, one should use $ThresholdTIEvaluation$ because it proved to be slightly better than the others. However, in cases when the local Slips instance has some local knowledge about the targets the $MaxConfidenceTIEvaluation$ might be a better choice.

For cases where the Fides communicates with some pre-trusted peers, one should use the $DistanceBasedTIEvaluation$ threat intelligence evaluation strategy in combination with $AverageConfidenceTIAggregation$. 
This combination is even able to guarantee that with at least 25\% of pre-trusted peers, it is able to eventually determine correct threat intelligence for all the targets.