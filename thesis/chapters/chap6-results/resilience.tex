\section{Fides Resilience}
\label{sec:fides-resilience}

In order to evaluate Fides's resilience in many different scenarios, we wanted to discover what is the Fides's configuration of interaction evaluation strategy~(\ref{sec:interaction-evaluation-strategies}), threat intelligence aggregation function~(\ref{sec:network-intelligence-aggregation}) and initial reputation~(\ref{subsubsec:computing-reputation}) that should be used in order to correctly classify targets in \textit{any} network topology.\footnote{Distribution of correct/uncertain/incorrect/malicious peers in the network.}
In other words, what setup should Fides's administrator use in order for Fides to guarantee that it will be able to \textit{eventually} classify targets correctly.

We discovered that the situation, when the administrator uses a particular setup which then guarantees that the Fides will be able to eventually classify the targets, exists. When the Fides communicates with at least 25\% of pre-trusted peers from its own network ($0.25 \cdot |P|$ are pre-trusted) and uses $DistanceBasedTIEvaluation$~(\ref{subsec:distance-based-eval}) for evaluating the interactions in combination with $AverageConfidenceTIAggregation$~(\ref{subsec:AverageConfidenceTIAggregation}) for aggregating the threat intelligence, it is able to classify the targets correctly no matter what is happening in the network.

\subsection{Correct Target Identification Under Harsh Conditions}
\label{subsec:correct-target-identification-no-matter-what}

The figure~\ref{fig:performance-all-setups-25-pretrusted} visualizes this situation where there are 25\% of pre-trusted peers in the network and shows how different configurations perform under different network distributions.
There are three rows and four columns. Each row contains a single interaction evaluation strategy~(\ref{sec:interaction-evaluation-strategies}) and each column is then a single metric that evaluates the behavior of this strategy in the network.
There are three different metrics that evaluate the performance of the Fides's setup and the last graph then displays how many confident correct~(\ref{subsubsec:confident-correct-peer}) peers there are in the network.
The horizontal axis in each graph measures the environment hardness explained in the section~\ref{subsec:environment-hardness}.
The vertical axis is then different for each metric.

As mentioned previously, there are three different metrics.
The first column is a metric measuring target detection performance~(\ref{subsec:target-detection-performance-metric}), the second is peers behavior detection metric~(\ref{subsec:peers-behavior-detection-performance-metric}) and the third column then measures average service trust $st^{kmax}_{i, j}$ for all peers in the simulation.

The last, fourth, column then contains a graph that displays what percentage of peers in the simulation were confident correct~(\ref{subsubsec:confident-correct-peer}) with respect to the environment hardness value~(\ref{subsec:environment-hardness}).
We include it in the graph to allow better visualization of how does the simulation environment looks like with respect to the peer's distribution.

The most important metric is the target detection performance ~(\ref{subsec:target-detection-performance-metric}), which is visualized on the first graph.
A single dot in the graph is the value of $tdp$ and in a case when the $tdp \geq 1$, it means that Fides made on the average wrong decision about the targets and classified them with the wrong label.
In other words, if $tdp \geq 1$, Fides classified benign targets as malicious and the other way around.

\begin{figure}
    \centering
    \includegraphics[width=0.94\paperwidth, angle=90]{assets/25_all_metrics.png}
    \caption{Performance of all setups with 25\% pre-trusted peers}
    \label{fig:performance-all-setups-25-pretrusted}
\end{figure}

In figure~\ref{fig:distance-detection-detail-25} we can clearly see, that there is a situation, even in the hardest environment, where the $DistanceBasedTIEvaluation$ in combination with $AverageConfidenceTIAggregation$ does not have any $tdp$ above the \textit{red line} which means that the $tdp < 1$ and that Fides was always able to identify targets correctly even in the worst possible environment.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/25_distance_detection_detail.png}
    \caption{$DistanceBasedTIEvaluation$ with 25\% of pre-trusted peers}
    \label{fig:distance-detection-detail-25}
\end{figure}

We included the graph of this case similar to the figure~\ref{fig:single-simulation-example} with this particular \textit{"winning"} setup in the most hostile environment to the appendix in figure~\ref{fig:worst-best-scenario}. For the explanation of the graph see section~\ref{sec:general-overview-of-simulation-output}.

Interestingly, in this particular case, the initial reputation does not affect the final outcome of the simulation, but it does affect the progress as when using an initial reputation higher than $0$, the Fides provides wrong scores in a situation when the malicious peers started to lie.
However, it discovers that the peers are lying, which decreases their service trust and is able to eventually recover the correct labels for the targets.
We included the graph for this situation in the appendix in figure~\ref{fig:missclassification-recovery}.

It is clear from the figure~\ref{fig:distance-detection-detail-25}, that when Fides used the threat intelligence aggregation method  $WeightedAverageConfidenceTIAggregation$~(\ref{subsec:WeightedAverageConfidenceTIAggregation}), it miss-classified the targets in one situation.
Thus, this method does not provide a guarantee that Fides will end up with correct classifications for every target.

\subsection{Resilience Under Different Conditions}
\label{subsec:resilience-under-different-conditions}

We include a similar graph to the figure~\ref{fig:performance-all-setups-25-pretrusted} for the situations with no pre-trusted peers in the appendix in the figure~\ref{fig:performance-all-setups-0-pretrusted} and then situation with 50\% of pre-trusted peers in the figure~\ref{fig:performance-all-setups-50-pretrusted}.

With no pre-trusted peers in the network, the results of each configuration vary and it highly depends on the network topology as well as on the knowledge of the local Slips instance.

However, in the case of 50\% pre-trusted peers, one can see that no matter the configuration, Fides was eventually able to determine the correct target classification with high precision of $tdp \leq 0.7$. Moreover, Fides was able to correctly identify the peer's behavior with the precision of $pbdp \leq 0.2$.